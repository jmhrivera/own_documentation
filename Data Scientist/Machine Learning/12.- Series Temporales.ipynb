{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Temporales\n",
    "\n",
    "Las series temporales son conjuntos de datos que están ordenados en función del tiempo. En otras palabras, representan observaciones o mediciones que se han recopilado en intervalos regulares de tiempo, como días, meses, horas, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es muy importante tener definidas las columnas de fechas para trabajar con series temporales, al importar tu archivo a pandas, puedes indicarle que columnas necesitas que usen el formato fecha con el parametro parse_date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Componentes de Series de Tiempo**\n",
    "\n",
    "- Tendencia Secular: Componente de largo plazo, que representa el crecimiento o drecremento en la serie sobre un periodo amplio\n",
    "\n",
    "- Variaciones Ciclicas: Variaciones de largo plazo que no son debidas a la estacionalidad y que se repiten a intervalos irregulares.\n",
    "\n",
    "- Componente Estacional: Patrones recurrentes o periódicos que se repiten en intervalos regulares, como estaciones del año o meses.\n",
    "\n",
    "- Variaciones Irregulares: Variaciones aleatorias o no sistemáticas que no pueden ser atribuidas a los componentes anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('D:/Tripleten/datasets/energy_consumption.csv', index_col=[0], parse_dates=[0]) #parse dates transforma las columnas indicadas a formato fecha\n",
    "\n",
    "data.sort_index(ascending=True, inplace=True)\n",
    "print(data.index.is_monotonic_increasing)\n",
    "# print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden realizar busquedas solo especificando la comparacion entre años `data['2016':'2018]` o años y meses `data['2016-01':'2016-12']  `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = data['2018-01':'2018-12'].resample('ME').mean().plot(title='Media de Consumo electrico por Mes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Media móvil\n",
    "\n",
    "La media móvil o promedio móvil es un método para suavizar los datos en una serie temporal.  El método consiste en encontrar los valores menos susceptibles a fluctuaciones, es decir, la media aritmética.\n",
    "\n",
    "En python se establece a través de la funcion rolling() en donde se especifica el número de media aritmeticas a tomar y se complementa con la función deseada (suma, media, maximo, desviación std, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mobile_mean =  data['2015':'2018'].resample('QE').sum()\n",
    "mobile_mean['std'] = mobile_mean.rolling(3).std()\n",
    "\n",
    "mobile_mean.plot(title='Serie Temporal')\n",
    "mobile_mean['std'].plot(color='orange')\n",
    "plt.legend(['MW_Consumption', 'Standard Deviation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tendencias y Estacionalidad\n",
    "\n",
    "- Tendencia: Una tendencia es un cambio ligero del valor medio de la serie sin repetir patrones. Por ejemplo, el incremento anual en la venta de boletos de avión.\n",
    "- Estacionalidad: significa patrones que se repiten de forma cíclica en una serie temporal. Por ejemplo, el crecimiento de las ventas de boletos de avión cada verano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "data = pd.read_csv('D:/Tripleten/datasets/energy_consumption.csv', index_col=[0], parse_dates=[0]) #parse dates transforma las columnas indicadas a formato fecha\n",
    "data.sort_index(ascending=True, inplace=True)\n",
    "data = data['2013':'2018'].resample('1ME').sum()\n",
    "decomposed = seasonal_decompose(data)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.subplot(311)\n",
    "decomposed.trend.plot(ax=plt.gca())\n",
    "plt.title('Tendencia')\n",
    "plt.subplot(312)\n",
    "decomposed.seasonal['2013':'2014'].plot(ax=plt.gca()) # Es posible filtrar con los datos ya procesados.\n",
    "plt.title('Estacionalidad')\n",
    "plt.subplot(313)\n",
    "decomposed.resid.plot(ax=plt.gca())\n",
    "plt.title('Residuales')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diferencias de series temporales\n",
    "\n",
    "Diferencias de series temporales es una secuencia de diferencias entre elementos vecinos de una serie temporal (es decir, el valor anterior se resta del siguiente).\n",
    "\n",
    "El método shift() se usa para encontrar las diferencias de series temporales. Todos los valores se desplazan un paso hacia adelante a lo largo del eje de tiempo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([0.5, 0.7, 2.4, 3.2])\n",
    "\n",
    "data -= data.shift(fill_value=0)\n",
    "\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronóstico de series temporales\n",
    "\n",
    "El objetivo del pronóstico de series temporales es desarrollar un modelo que prediga los valores futuros de una serie temporal con base en datos anteriores.\n",
    "\n",
    "El periodo en el futuro para el que se prepara el pronóstico se conoce como horizonte de pronóstico. Para los ejercicios de este capítulo usaremos un horizonte de un paso. Es muy importante que al entrenar un modelo dividamos los datos en entrenamiento y test, sin embargo a diferencia de otros modelos, nuestros datos no deberán de ser mezclados aleatoriamente, ya que arruinaria la continuidad de nuestra serie temporal, en su lugar aplicaremos el parametro `shuffle=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.Series([0.1, 0.5, 2.3, 1.2, 1.5])\n",
    "train, test = train_test_split(data, shuffle=False, test_size=1/5) # Desactivamos shuffle para series temporales\n",
    "print('Conjunto de entrenamiento:')\n",
    "print(train)\n",
    "print('Conjunto de prueba:')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exactitud del pronóstico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "data = pd.read_csv(\n",
    "    'D:/Tripleten/datasets/energy_consumption.csv', index_col=[0], parse_dates=[0]\n",
    ")\n",
    "data.sort_index(inplace=True)\n",
    "data = data.resample('1D').sum()\n",
    "\n",
    "train, test = train_test_split(data, shuffle=False, test_size=0.2)\n",
    "\n",
    "print('Consumo medio diario de energía:', test['PJME_MW'].median())\n",
    "\n",
    "pred_previous = test.shift()  # Con esto se reemplazan los valores al día siguiente y el primer valor se queda en 0\n",
    "pred_previous.iloc[0] = train.iloc[-1] # Con esto traemos el último día de train y se lo ponemos al primer día de test\n",
    "print('EAM:', mean_absolute_error(test, pred_previous))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de características\n",
    "\n",
    "Caracteristicas de calendario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/Tripleten/datasets/energy_consumption.csv', index_col=[0], parse_dates=[0])\n",
    "data.sort_index(inplace=True)\n",
    "data = data.resample('1D').sum()\n",
    "\n",
    "# esta característica contiene años como valores numéricos\n",
    "data['año'] = data.index.year\n",
    "\n",
    "# esta característica contiene días de la semana como valores numéricos\n",
    "data['díadelasemana'] = data.index.dayofweek\n",
    "\n",
    "# esta característica contiene días de la semana como valores numéricos\n",
    "data['día'] = data.index.day\n",
    "\n",
    "# esta característica contiene días de la semana como valores numéricos\n",
    "data['mes'] = data.index.month\n",
    "\n",
    "print(data.sample(8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Características de desfase\n",
    "\n",
    "Los valores anteriores en la serie temporal te dirán si la función x(t) aumentará o disminuirá. Vamos a usar la función shift() para obtener los valores de desfase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lag_1'] = data['PJME_MW'].shift(1, fill_value=0) # En caso de que queramos rellenar\n",
    "data['lag_2'] = data['PJME_MW'].shift(2)\n",
    "data['lag_3'] = data['PJME_MW'].shift(3)\n",
    "\n",
    "data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora un ejercicio aplicando todo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = pd.read_csv(\n",
    "    'D:/Tripleten/datasets/energy_consumption.csv', index_col=[0], parse_dates=[0]\n",
    ")\n",
    "data.sort_index(inplace=True)\n",
    "data = data.resample('1D').sum()\n",
    "\n",
    "def make_features(data, max_lag, rolling_mean_size):\n",
    "    data['year'] = data.index.year\n",
    "    data['month'] = data.index.month\n",
    "    data['day'] = data.index.day\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    \n",
    "    for lag in range(1, max_lag + 1):\n",
    "        data['lag_{}'.format(lag)] = data['PJME_MW'].shift(lag)\n",
    "\n",
    "    data['rolling_mean']= data['PJME_MW'].shift().rolling(rolling_mean_size).mean()\n",
    "\n",
    "make_features(data, 4, 4)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series Temporales con Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAM para el conjunto de entrenamiento: 33620.831381001844\n",
      "EAM para el conjunto de prueba: 36776.40327032028\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "data = pd.read_csv(\n",
    "    'D:/Tripleten/datasets/energy_consumption.csv', index_col=[0], parse_dates=[0]\n",
    ")\n",
    "data.sort_index(inplace=True)\n",
    "data = data.resample('1D').sum()\n",
    "\n",
    "def make_features(data, max_lag, rolling_mean_size):\n",
    "    data['year'] = data.index.year\n",
    "    data['month'] = data.index.month\n",
    "    data['day'] = data.index.day\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "\n",
    "    for lag in range(1, max_lag + 1):\n",
    "        data['lag_{}'.format(lag)] = data['PJME_MW'].shift(lag)\n",
    "\n",
    "    data['rolling_mean'] = (\n",
    "        data['PJME_MW'].shift().rolling(rolling_mean_size).mean()\n",
    "    )\n",
    "\n",
    "\n",
    "make_features(data, 6, 10)\n",
    "\n",
    "train, test = train_test_split(data, shuffle=False, test_size=0.2)\n",
    "train = train.dropna()\n",
    "\n",
    "X_train = train.drop(columns=['PJME_MW'])\n",
    "y_train = train['PJME_MW']\n",
    "\n",
    "X_test = test.drop(columns=['PJME_MW'])\n",
    "y_test = test['PJME_MW']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "X_predict = model.predict(X_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "MAE_train = mean_absolute_error(y_train,X_predict)\n",
    "MAE_test = mean_absolute_error(y_test,y_predict)\n",
    "\n",
    "print(\"EAM para el conjunto de entrenamiento:\", MAE_train)\n",
    "print(\"EAM para el conjunto de prueba:\", MAE_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PJME_MW</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>lag_3</th>\n",
       "      <th>lag_4</th>\n",
       "      <th>lag_5</th>\n",
       "      <th>lag_6</th>\n",
       "      <th>rolling_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-01-01</th>\n",
       "      <td>714857.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-02</th>\n",
       "      <td>822277.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>714857.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-03</th>\n",
       "      <td>828285.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>822277.0</td>\n",
       "      <td>714857.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-04</th>\n",
       "      <td>809171.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>828285.0</td>\n",
       "      <td>822277.0</td>\n",
       "      <td>714857.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-01-05</th>\n",
       "      <td>729723.0</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>809171.0</td>\n",
       "      <td>828285.0</td>\n",
       "      <td>822277.0</td>\n",
       "      <td>714857.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30</th>\n",
       "      <td>790978.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>771910.0</td>\n",
       "      <td>827898.0</td>\n",
       "      <td>916596.0</td>\n",
       "      <td>917308.0</td>\n",
       "      <td>889492.0</td>\n",
       "      <td>921189.0</td>\n",
       "      <td>843245.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31</th>\n",
       "      <td>828938.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>790978.0</td>\n",
       "      <td>771910.0</td>\n",
       "      <td>827898.0</td>\n",
       "      <td>916596.0</td>\n",
       "      <td>917308.0</td>\n",
       "      <td>889492.0</td>\n",
       "      <td>838613.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01</th>\n",
       "      <td>941539.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>828938.0</td>\n",
       "      <td>790978.0</td>\n",
       "      <td>771910.0</td>\n",
       "      <td>827898.0</td>\n",
       "      <td>916596.0</td>\n",
       "      <td>917308.0</td>\n",
       "      <td>851115.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02</th>\n",
       "      <td>950233.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>941539.0</td>\n",
       "      <td>828938.0</td>\n",
       "      <td>790978.0</td>\n",
       "      <td>771910.0</td>\n",
       "      <td>827898.0</td>\n",
       "      <td>916596.0</td>\n",
       "      <td>870720.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03</th>\n",
       "      <td>35486.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>950233.0</td>\n",
       "      <td>941539.0</td>\n",
       "      <td>828938.0</td>\n",
       "      <td>790978.0</td>\n",
       "      <td>771910.0</td>\n",
       "      <td>827898.0</td>\n",
       "      <td>875608.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6059 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PJME_MW  year  month  day  dayofweek     lag_1     lag_2  \\\n",
       "Datetime                                                                \n",
       "2002-01-01  714857.0  2002      1    1          1       NaN       NaN   \n",
       "2002-01-02  822277.0  2002      1    2          2  714857.0       NaN   \n",
       "2002-01-03  828285.0  2002      1    3          3  822277.0  714857.0   \n",
       "2002-01-04  809171.0  2002      1    4          4  828285.0  822277.0   \n",
       "2002-01-05  729723.0  2002      1    5          5  809171.0  828285.0   \n",
       "...              ...   ...    ...  ...        ...       ...       ...   \n",
       "2018-07-30  790978.0  2018      7   30          0  771910.0  827898.0   \n",
       "2018-07-31  828938.0  2018      7   31          1  790978.0  771910.0   \n",
       "2018-08-01  941539.0  2018      8    1          2  828938.0  790978.0   \n",
       "2018-08-02  950233.0  2018      8    2          3  941539.0  828938.0   \n",
       "2018-08-03   35486.0  2018      8    3          4  950233.0  941539.0   \n",
       "\n",
       "               lag_3     lag_4     lag_5     lag_6  rolling_mean  \n",
       "Datetime                                                          \n",
       "2002-01-01       NaN       NaN       NaN       NaN           NaN  \n",
       "2002-01-02       NaN       NaN       NaN       NaN           NaN  \n",
       "2002-01-03       NaN       NaN       NaN       NaN           NaN  \n",
       "2002-01-04  714857.0       NaN       NaN       NaN           NaN  \n",
       "2002-01-05  822277.0  714857.0       NaN       NaN           NaN  \n",
       "...              ...       ...       ...       ...           ...  \n",
       "2018-07-30  916596.0  917308.0  889492.0  921189.0      843245.9  \n",
       "2018-07-31  827898.0  916596.0  917308.0  889492.0      838613.2  \n",
       "2018-08-01  771910.0  827898.0  916596.0  917308.0      851115.6  \n",
       "2018-08-02  790978.0  771910.0  827898.0  916596.0      870720.1  \n",
       "2018-08-03  828938.0  790978.0  771910.0  827898.0      875608.1  \n",
       "\n",
       "[6059 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adfuller() #para ver si tiene corrrelacion\n",
    "\n",
    "\n",
    "# df[].autocorr(lag=1)\n",
    "# df[].autocorr(lag=2)\n",
    "# df[].autocorr(lag=3)\n",
    "\n",
    "\n",
    "decompose = seasonal_compose(df[passengers], model= additive, period= 7) #el periodo son los cortes que queremos hacer(cada 7 meses) # Si los residuos estan en 1 esta saludable\n",
    "# Si los datos estan alrededor del 0 estan saludables.\n",
    "\n",
    "decompose = seasonal_compose(df[passengers], model= multiplicative , period= 7) # Si los residuos estan en 1 esta saludable\n",
    "\n",
    "# from pmdarima import auto_arima (((xxx moving avergare)))\n",
    "# sarimax modelo 2\n",
    "#prophet python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
