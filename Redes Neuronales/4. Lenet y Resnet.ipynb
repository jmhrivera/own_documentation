{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto ResNet como LeNet son arquitecturas de redes neuronales convolucionales (CNN) diseñadas para tareas de reconocimiento de imágenes y otras aplicaciones relacionadas con la visión por computadora. A continuación, te proporcionaré una breve descripción de cada una:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet\n",
    "\n",
    "LeNet es una de las primeras arquitecturas de redes neuronales convolucionales (CNN) y fue desarrollada por Yann LeCun y sus colegas en los años 90. Su versión más conocida es LeNet-5. Esta arquitectura se utilizó originalmente para la clasificación de dígitos escritos a mano en el conjunto de datos MNIST. Es una arquitectura simple y efectiva que sentó las bases para muchas arquitecturas de CNN modernas.\n",
    "\n",
    "Estructura de LeNet-5:\n",
    "Entrada (Input): Imágenes en escala de grises de tamaño 32x32 píxeles.\n",
    "- C1: Convolucional con 6 filtros de tamaño 5x5.\n",
    "- S2: Pooling promedio (average pooling) con tamaño de 2x2.\n",
    "- C3: Convolucional con 16 filtros de tamaño 5x5.\n",
    "- S4: Pooling promedio (average pooling) con tamaño de 2x2.\n",
    "- C5: Convolucional con 120 filtros de tamaño 5x5.\n",
    "- F6: Capa completamente conectada con 84 neuronas.\n",
    "- Salida (Output): Capa completamente conectada con 10 neuronas (para 10 clases de dígitos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "ResNet (Residual Network) es una arquitectura de red neuronal profunda desarrollada por Kaiming He y sus colegas, y fue introducida en el trabajo \"Deep Residual Learning for Image Recognition\" en 2015. ResNet ganó el concurso ImageNet en 2015 y es conocida por su capacidad para entrenar redes muy profundas mediante el uso de bloques residuales, que ayudan a mitigar el problema del desvanecimiento del gradiente.\n",
    "\n",
    "Profundidad: ResNet puede tener varias profundidades, como ResNet-18, ResNet-34, ResNet-50, ResNet-101 y ResNet-152, donde el número indica el número de capas en la red.\n",
    "\n",
    "Estructura básica de ResNet-50:\n",
    "\n",
    "- Entrada (Input): Imagen de tamaño 224x224 píxeles.\n",
    "- Convolución inicial: Convolución 7x7, seguida de max pooling 3x3.\n",
    "- Bloques residuales: Con múltiples capas (conv, batch norm, \n",
    "- ReLU, conv, batch norm, y suma con la entrada).\n",
    "- Bloques Residuales Profundos: Como en ResNet-50, se utilizan bloques residuales con más capas para permitir una mayor profundidad.\n",
    "- Capa completamente conectada: Al final, una capa completamente conectada con el número de clases correspondiente a la tarea (por ejemplo, 1000 clases en ImageNet)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparación y Uso\n",
    "\n",
    "- LeNet: Adecuada para tareas más simples y conjuntos de datos pequeños, como la clasificación de dígitos MNIST. Es una red relativamente poco profunda y más fácil de entrenar.\n",
    "- ResNet: Diseñada para tareas más complejas y conjuntos de datos grandes. Puede entrenarse con redes muy profundas, lo que la hace adecuada para aplicaciones avanzadas de visión por computadora, como ImageNet.\n",
    "\n",
    "En resumen, ambas arquitecturas son fundamentales en el campo de la visión por computadora, con LeNet siendo una pionera en las CNN y ResNet permitiendo el entrenamiento de redes muy profundas con un rendimiento sobresaliente.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
